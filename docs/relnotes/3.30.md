This AIStore release, version **3.30**, arrives two months after the previous release with a cycle spanning over 300 commits. As always, 3.30 maintains compatibility with the previous version and supports rolling upgrades.

This release adds the capability to handle [batch workloads](#batch-workflows). The idea is to serve hundreds or thousands of objects (or archived files) in a single serialized streaming (or multipart) response.

AIStore 3.30 delivers performance improvements across multiple subsystems, with particular focus on I/O efficiency, connection management, and [ETL](#etl) operations. The updated and restructured ETL subsystem now features direct filesystem access (by ETL containers), eliminates the WebSocket communicator’s io.Pipe bottlenecks, and enables the container to perform direct PUT operations. It also simplifies configuration using minimal runtime specs in place of full Kubernetes Pod YAML.

[Python SDK 1.15](#python-sdk) introduces high-performance batch processing with streaming decode for large archives and powerful new ETL capabilities. This breaking release removes the deprecated `init_code` ETL API while adding improved resilience with better retry logic.

For observability, Prometheus now exports disk write latency and pending I/O depth metrics, with automatic capacity refresh triggered by disk alerts. StatsD exporters, while still available, are now disabled by default as we transition to Prometheus and OpenTelemetry as first-class monitoring solutions.

For tooling, the CLI gains a new [`ml` namespace](https://github.com/NVIDIA/aistore/blob/main/docs/cli/ml.md) with [Lhotse](https://github.com/lhotse-speech/lhotse) CutSet helpers for ML pipelines. This CLI upgrade also delivers [Hugging Face](https://huggingface.co/api/datasets) repository integration (including batched downloads) and multiple usability improvements.

Cloud backend enhancements include Oracle Cloud Infrastructure multipart upload support enabling S3 clients (boto3, s3cmd, AWS CLI, etc.) to perform multipart uploads against OCI backends without code changes, plus AWS configuration management improvements and related bug fixes.

New `ais object cp` and `ais object etl` commands (and the respective APIs) provide synchronous copy and transform operations without engaging asynchronous multi-object xactions (batch jobs).

[Documentation](#documentation) updates include a complete ETL CLI (docs) rewrite, new operational guides for connection management and ML workflows, enhanced Python SDK documentation, and improved AWS backend configuration guidance.

Infrastructure improvements include automatic macOS/arm64 CLI binary builds for GitHub releases and upgrades to all open-source dependencies (except Kubernetes client libraries), bringing security patches and performance improvements across the codebase.

## Table of Contents

1.  [Batch Workflows](#batch-workflows)
2.  [ETL](#etl)
3.  [Performance & Scalability](#performance)
4.  [Observability](#observability)
5.  [CLI](#cli)
6.  [Python SDK 1.15](#python-sdk)
7.  [Single Object Copy/Transform](#single-object)
8.  [Cloud Backend Enhancements](#backends)
9.  [Bug and Security Fixes](#bug-and-security)
10. [Build & CI](#build)
11. [Documentation](#documentation)
12. [Deprecations & Compatibility](#deprecations)

Detailed changelog is available at this [link](https://github.com/NVIDIA/aistore/compare/v1.3.29...v1.3.30).

<a name="batch-workflows"></a>
## 1. Batch Workflows

AIStore 3.30 introduces the new `GetBatch` API. Instead of reading objects and files one at a time, you bundle any number of items — plain objects and/or archived files — into a single request. The cluster then streams back the entire batch as an ordered archive, eliminating multiple network round-trips. Location wise, the specified data items can reside in-cluster or in remote (cloud) buckets.

The response itself may be streaming or multipart, with formatting options that universally include (.tar, .tar.gz, .tar.lz4, and .zip).

The response always preserves the specified order, and in streaming mode it begins flowing immediately so you don’t have to wait for the entire archive to assemble. If you enable ‘continue on error,’ missing files won’t halt the request — instead, those items appear as zero-length files with a special prefix, and the transfer proceeds with the remaining data.

### Lhotse Integration

AIStore 3.30's first vertical `GetBatch` integration supports [Lhotse](https://github.com/lhotse-speech/lhotse) speech-processing toolkit.
You can now provide a Lhotse CutSet (`cuts.jsonl` or `.gz` or `.lz4`) to the CLI, and AIStore will assemble each cut's audio frames into training-ready serialized (.tar | .tar.gz | .tar.lz4 | .zip) files.

In your batch manifest, each entry can reference one of the following:

- A complete object (`bucket/audio.wav`)
- A file within an archive (`shard.tar/images/003.jpg`)
- A time range in seconds (`start_time,duration`) from Lhotse cuts¹

This integration is intended for speech ML pipelines where audio files are often stored as compressed archives, training requires precise range extraction, and batch sizes can reach thousands of `cuts`.

AIStore's batch processing groups cuts by source file, minimizing redundant reads when multiple cuts reference the same audio file. Rather than reading byte ranges (which would require multiple I/O operations per file), the system downloads complete files once and performs cut extraction in-memory, delivering superior performance for typical speech training workloads.

Further, large manifests can be automatically split using `--batch-size` and `--output-template` parameters, producing multiple equal-sized archives instead of one massive output.

---

¹ *Note: Current implementation processes complete audio files and extracts cuts in-memory for optimal I/O efficiency. Byte-range reading support can be added upon request, though this would impact performance for workloads with multiple cuts per file.*

### CLI Examples

```console
# Stream a cross-bucket batch directly to disk
ais ml get-batch output.zip --spec manifest.yaml --streaming

# Process Lhotse cuts into 1000-sample shards
ais ml lhotse-get-batch --cuts training.cuts.jsonl.lz4 \
                        --batch-size 1000 \
                        --output-template "shard-{001..999}.tar"
```

### Python SDK Integration

```python
from aistore.sdk.batch import BatchRequest, BatchLoader

# Build streaming batch request
req = BatchRequest(streaming=True, continue_on_err=True)
req.add_object_request(obj, archpath="img/0001.jpg", opaque=b"metadata")

# Execute with streaming decode
stream = BatchLoader(cluster_url).get_batch(
    req, return_raw=True, decode_as_stream=True
)
```

### Commit Highlights

- [2f18344e](https://github.com/NVIDIA/aistore/commit/2f18344e): Complete CLI refactor for batch operations
- [404d0011](https://github.com/NVIDIA/aistore/commit/404d0011): Implement streaming path with memory optimization
- [726da0d](https://github.com/NVIDIA/aistore/commit/726da0d): Multi-batch generator with automatic chunking
- [0affbd75](https://github.com/NVIDIA/aistore/commit/0affbd75): Ordered multi-node assembly protocol
- [f8ee6c2d](https://github.com/NVIDIA/aistore/commit/f8ee6c2d): Shared stream pool implementation

<a name="etl"></a>
## 2. ETL

AIStore 3.30 represents a major restructure of the ETL component that consumed the majority of this development cycle. The overhaul focused primarily on performance improvements, introducing direct PUT operations and eliminating io.Pipe (in the previous WebSocket-based implementation) that were limiting throughput at scale. This restructure required breaking changes to the ETL metadata format and removal of the deprecated init-code API, while also adding automatic filesystem access and a two-phase commit protocol for deployment reliability.

### Performance-Focused Restructure

The core motivation for this restructure was addressing performance bottlenecks that became apparent under heavy production workloads. The previous ETL architecture suffered from sub-optimal data flows that created significant overhead for large-scale transformations.

**Direct PUT Operations**: ETL containers can now write transformed objects directly back to AIStore targets without intermediate hops or staging. This eliminates a full network round-trip and the associated serialization overhead, dramatically improving throughput for write-heavy transformations. Previously, transformed data had to flow back through the proxy layer, creating both latency and bandwidth bottlenecks.

**WebSocket io.Pipe Elimination**: The WebSocket communicator has been completely rewritten to remove the io.Pipe bottleneck that was causing blocking I/O operations. The new implementation writes directly to file handles instead of using goroutine-coordinated pipes, eliminating unnecessary buffering, memory allocation pressure, and synchronization overhead. This change alone reduces goroutine count by thousands for large ETL jobs.

**Streamlined Transport Layer**: The per-job transport mechanism now uses a single read-write loop rather than complex goroutine orchestration, reducing resource consumption and improving predictability under load. A one-million-object ETL run on a 20-node cluster now operates with significantly lower memory footprint and CPU overhead.

### Breaking Changes

This restructure required two significant breaking changes that affect existing ETL workflows.

**ETL Metadata Format**: The metadata format has been updated to support the new performance architecture and deployment protocols. Clusters must achieve uniform version status before starting new ETL operations to ensure consistent behavior across all nodes during the transition period.

**init_code API Removal**: The deprecated `init_code` method for ETL initialization has been completely removed. This legacy API was incompatible with the new performance optimizations and security model. Users must migrate to the `init_class` method or specification-based initialization, both of which provide better error handling, resource management, and integration with the new direct PUT capabilities.

### Simplified Runtime Specification

Version 3.30 introduces a much simpler configuration model. The new ETL runtime specification replaces complex Kubernetes Pod YAML with a concise, portable format that focuses on the essentials — container image, communication preferences. For more details on the new specification, see [ETL runtime specification](https://aistore.nvidia.com/docs/etl#1-runtime-specification-recommended).

 ```
 name: my-transformer
 runtime:
   image: my-etl-image:latest
   communication_type: ws  # optional, defaults to hpush
```

This specification behaves the same way across the REST API, CLI commands, and Python SDK — preventing configuration drift between development and production environments, which was a frequent source of deployment issues in the past.

### Automatic Filesystem Access

Direct filesystem access through Fully Qualified Names (FQN) is now completely automatic, leveraging the performance improvements to provide zero-configuration high-speed data access. Targets automatically query the Kubernetes API for their persistent volume claims, mount them read-only into ETL containers, and coordinate path handling across the cluster without user intervention.

This automation eliminates the manual PVC identification, volume mount configuration, and environment variable management that previously made FQN access difficult to set up correctly, while delivering significant performance benefits for data-intensive transformations.

### Two-Phase Commit Protocol

To ensure the restructured ETL system deploys reliably at scale, version 3.30 adds a two-phase commit protocol for initialization. The process ensures atomic deployment across the entire cluster: every target must successfully prepare (pull and start the ETL image) before any target commits to running the job. If any node fails during preparation, the system performs global cleanup and marks the deployment as aborted.

This eliminates partial deployments where jobs appear to be running but are only processing data on a subset of nodes, a common source of silent failures in distributed ETL pipelines.

### Enhanced Observability

The restructure includes comprehensive observability improvements. Every object-level transformation failure is logged with detailed reason codes in a failure registry, accessible via `ais etl show errors <ETL-NAME> <JOB-ID>` for rapid debugging of production issues.

New Prometheus metrics track ETL performance including total bytes processed, object counts, and transform latency distributions. The CLI gains multi-document YAML support, remote URL specifications for sharing transformations, automatic spec verification, and single-object transform calls for testing.

### Python SDK Integration

The Python SDK has been updated to take advantage of the restructured architecture. The new `init_class` method provides a streamlined approach for pure Python ETLs without requiring local containerization tools, while context manager support ensures proper resource cleanup.

Runtime package installation via environment variables (`PACKAGES` for PyPI, `OS_PACKAGES` for system packages) integrates with the new direct PUT capabilities to provide a complete high-performance ETL development experience.

### Commit Highlights

- [d738644](https://github.com/NVIDIA/aistore/commit/d738644): Implement 2-PC skeleton with locking protocol
- [2971e9a](https://github.com/NVIDIA/aistore/commit/2971e9a): Add proxy stage manager for cluster coordination
- [37923a85](https://github.com/NVIDIA/aistore/commit/37923a85): WebSocket refactor removing io.Pipe bottleneck
- [5223d469](https://github.com/NVIDIA/aistore/commit/5223d469): Cluster-wide abort mechanism with cleanup
- [1ba44ab2](https://github.com/NVIDIA/aistore/commit/1ba44ab2): New Prometheus metrics for ETL monitoring

<a name="performance"></a>
## 3. Performance & Scalability

Beyond the major [ETL](#etl) restructure, AIStore 3.30 includes targeted performance optimizations across the storage and networking layers that improve efficiency under high-load conditions.

### Adaptive Read Buffer Optimization

The storage subsystem now employs intelligent read buffering that selects optimal buffer sizes from AIStore's existing [memsys](https://github.com/NVIDIA/aistore/tree/main/memsys) package, which provides fixed-size slabs of reusable buffers and SGLs ranging from 4K to 128K in 4K increments.

This seemingly simple change to buffer selection logic has proven remarkably effective, increasing average read sizes and, correspondingly, reducing IOPS across read operations.

The optimization applies universally to range reads, archive extractions, and standard object reads, with performance benchmarks showing 2x-3x improvements in read size efficiency.

### Idle connections

AIStore now enforces a 30-second idle timeout on the listening side. This change primarily reduces the number of active goroutines during stressful conditions, when connection pools can grow to thousands of idle connections waiting for cleanup.

The timeout mechanism improves overall resource utilization including file descriptor management, memory footprint, and goroutine scheduler overhead. Under typical production workloads with burst traffic patterns, this prevents resource exhaustion that could otherwise impact cluster stability during peak usage periods.

### Shared Data Mover (SDM)

A new cluster-wide [stream pool](https://github.com/NVIDIA/aistore/tree/main/transport#description) provides long-lived, reusable peer-to-peer connections across multiple batch operations. Rather than establishing fresh connections for each job, the shared data mover maintains a pool of established intra-cluster connections that can be reused across different operations, reducing connection establishment overhead and improving overall throughput consistency.

Currently, shared data mover is only utilized by [GetBatch](#batch-workflows) requests, with future plans to extend this infrastructure to other job [kinds](https://github.com/NVIDIA/aistore/blob/main/docs/batch.md) as SDM proves its value in production deployments.

### Commit Highlights

- [4bcff7ce](https://github.com/NVIDIA/aistore/commit/4bcff7ce): Implement adaptive read buffers with dynamic sizing
- [67ce50ae](https://github.com/NVIDIA/aistore/commit/67ce50ae): Add idle connection timeout and limit the number of idle connections
- [b2a54b3d](https://github.com/NVIDIA/aistore/commit/b2a54b3d): TCB, TCO, list-range jobs: tune-up 'num-workers' at runtime

<a name="observability"></a>
## 4. Observability

AIStore 3.30 includes targeted [monitoring]( https://github.com/NVIDIA/aistore/blob/main/docs/monitoring-overview.md) improvements focused on disk-level capacity tracking and Prometheus integration fixes.

### Disk-Level Capacity Alerts

Previous versions relied on node-level capacity alerts that averaged storage usage across all disks, which proved insufficient for real-world scenarios. This limitation became apparent when a 2.4TiB file placed in an S3 backend was retrieved by AIStore, resulting in 11 disks at 50% capacity while the 12th disk reached 90% utilization. The node-level average would have shown approximately 53% usage, masking the critical storage situation on the individual disk.

Version 3.30 adds two disk-specific alerts: low-capacity and out-of-space warnings that trigger on individual disk thresholds rather than cluster or node averages. These alerts provide the granular visibility needed to detect and respond to uneven storage distribution before it impacts cluster operations.

### Reactive Capacity Management

Any disk alert now triggers an immediate capacity refresh across the cluster, ensuring that capacity reporting remains current even during storage events. This enhancement provides real-time visibility into storage changes and enables proactive cluster rebalancing when individual disks approach capacity limits.

### Prometheus Integration Fix

A simple but significant bug fix ensures that existing disk metrics now appear correctly in Prometheus monitoring. AIStore has always tracked comprehensive storage metrics including disk read/write bytes per second, average I/O sizes, disk utilization, and a complete 64-bit bitwise alert field covering out-of-space, out-of-memory, and other conditions. These metrics worked correctly with StatsD exporters, but the Prometheus implementation was missing the necessary `set` calls on the underlying metrics, causing them to be missing in Prometheus dashboards.

### Commit Highlights

- [634baafe](https://github.com/NVIDIA/aistore/commit/634baafe): Add two disk-level alerts: low-capacity and out-of-space
- [a8835833](https://github.com/NVIDIA/aistore/commit/a8835833): Always refresh cached capacity numbers upon node-level alerts _or_ any disk alerts
- [71f3c21f](https://github.com/NVIDIA/aistore/commit/71f3c21f): Fix node-state and disk gauge accuracy

<a name="cli"></a>
## 5. CLI

The command-line interface receives useful improvements in version 3.30, primarily focused on usability, error handling, machine learning workflows, and download capabilities.

### Machine Learning Namespace

A new `ml` command group provides dedicated functionality for ML practitioners working with batch data processing. The namespace currently includes `ais ml get-batch` for native batch retrieval with custom manifests and `ais ml lhotse-get-batch` for specialized Lhotse CutSet processing. These commands are designed to simplify batch loading workflows without requiring deep AIStore knowledge.

### HuggingFace Download Integration

The existing `ais download` command has been extended with HuggingFace repository support through new flags including `--hf-model`, `--hf-dataset`, `--hf-file`, `--hf-auth`, and `--hf-revision`. This integration allows downloading models and datasets directly from HuggingFace repositories into AIStore buckets.

A useful addition is optimized batching based on file size thresholds. When using `--blob-threshold`, the system automatically makes concurrent HEAD requests to determine file sizes, then separates large files (which get individual download jobs for better parallelism) from small files (which get batched together for efficiency). This optimization addresses the common scenario where HuggingFace repositories contain mixed file sizes ranging from small configuration files to multi-gigabyte model weights.

### Enhanced Command Discover-ability

The alias handling system has been rewritten with a focus to support intuitive across different namespaces. The motivation stems from user experience challenges where related functionality exists in multiple places. For example, ais object etl transforms a single object (logically placed in the object namespace), while ais etl provides ETL management commands.

The new [utility](https://github.com/NVIDIA/aistore/blob/main/cmd/cli/cli/make_alias.md) allows to easily clone commands across namespaces while fixing usage text and adapting flags for each context. This enables the same underlying functionality to appear where users naturally expect it, with appropriate help text and flag sets for each namespace.

The system reduces CLI codebase complexity by eliminating repetitive boilerplate while improving user experience through better command discoverability.

### Usability Enhancements

Several convenience flags improve day-to-day operations including `--all` options for bulk eviction and bucket removal, template-based output naming for shard generation, and `--top` filtering for job listings. The CLI also gains enhanced help output with better examples and usage patterns.

Administrative capabilities include `ais advanced check-lock` for lock management and debugging, improved error display grouping for ETL operations, and better progress handling with timeout fixes.

### Commit Highlights

- [59da3f90](https://github.com/NVIDIA/aistore/commit/59da3f90): Add ML namespace and `ais ml get-batch` command
- [78a50eda](https://github.com/NVIDIA/aistore/commit/78a50eda): Apply batching on HuggingFace downloads with size-based job splitting
- [6485efaa](https://github.com/NVIDIA/aistore/commit/6485efaa): Rewrite alias system for consistency and reduced complexity
- [c375ffe2](https://github.com/NVIDIA/aistore/commit/c375ffe2): Unwrap API errors robustly; create destination with refactoring
- [b25eaafb](https://github.com/NVIDIA/aistore/commit/b25eaafb): Add template support to shard generation
- [75a7a6f9](https://github.com/NVIDIA/aistore/commit/75a7a6f9): Implement bulk operations with `--all` flag

<a name="python-sdk"></a>
## 6. Python SDK 1.15

The Python SDK receives significant updates in its version 1.15, primarily introducing the `Get Batch` API and improving ETL usability alongside better resilience for operations under intermittent network conditions.

### ETL Framework Updates

The SDK now provides multiple initialization approaches for ETL jobs, including `etl.init()` for launching jobs directly from container images without specification files, and the new `etl.init_class()` method for pure Python ETLs that eliminates the need to build container images. The deprecated `etl.init_code()` API has been removed as a breaking change, replaced by the `init_class()` decorator approach for ETL webserver classes.

ETL management gains improved inspection capabilities through enhanced `etl.view()` functionality, while the webserver framework includes transformed object sizes in direct PUT responses and introduces serialization utilities for ETLServer subclasses. The default web server port for Python ETLs has been changed from port 80 to port 8000 for better compatibility with development environments.

API naming has been modernized with `Cluster.list_running_etls()` renamed to `Cluster.list_etls()` and now accepts an ptional stage filter parameter. ETL stage terminology has been updated from "Stopped" to "Aborted" for improved clarity about job states.

### Get Batch API

The new [BatchLoader](https://github.com/NVIDIA/aistore/blob/main/python/aistore/sdk/batch/batch_loader.py) represents a substantial addition to the SDK, providing efficient retrieval and processing of multiple objects from AIStore clusters through a sophisticated multipart HTTP response system.

The implementation handles complex scenarios including data stored across multiple objects, archives, buckets, and providers within an AIStore cluster.

The architecture centers around core components including `MultipartDecoder` for parsing multipart HTTP responses, along with `BatchLoader`, `BatchRequest`, and `BatchResponseItem` data structures that coordinate request handling and response processing.

The system supports both streaming and non-streaming modes with flexible options for raw response access or automatic content extraction.

Streaming capabilities enable memory-efficient processing of large datasets through `ArchiveStreamExtractor` for extracting archive contents and a `parse_as_stream` option in MultipartDecoder.
This allows processing large batches without loading entire responses into memory, addressing real-world scenarios where batch sizes can reach thousands of objects.

Note that `BatchLoader` is currently in active development and subject to change based on usage patterns and user feedback.

### Resilience Improvements

Error handling and retry mechanisms have been enhanced for better reliability under network instability. The AISRetryConfig gains `cold_get_conf` settings for configuring retry behavior specifically for cold GET operations, while RequestClient now includes delay logic for retry attempts on ReadTimeoutError conditions during remote object fetches. These improvements provide better handling of transient network issues and connection failures that are common in distributed storage environments.

### API Enhancements

Single object operations are simplified through the new `Object.copy()` method that supports ETLConfig parameters for copying and transforming objects in a single call, integrating seamlessly with the cluster's single object copy functionality. Archive support expands with `Bucket.list_archive()` providing a helper method to list contents inside archived objects with options to include the archive file itself in the listing.

### Commit Highlights

- [c8fbec70](https://github.com/NVIDIA/aistore/commit/c8fbec70): Implement streaming decoder for large archives
- [96a312d9](https://github.com/NVIDIA/aistore/commit/96a312d9): Add raw byte access parameter
- [089af07e](https://github.com/NVIDIA/aistore/commit/089af07e): Remove deprecated arguments from BatchLoader
- [748f696b](https://github.com/NVIDIA/aistore/commit/748f696b): Release version 1.15.0 with auto-generated docs

<a name="single-object"></a>
## 7. Single Object Copy/Transform

AIStore 3.30 adds single object copy and transform functionality following the Amazon S3 [CopyObject API](https://docs.aws.amazon.com/AmazonS3/latest/API/API_CopyObject.html) pattern.

Previously, operations like `ais object cp` and `ais object etl` would engage the full TCB/TCO batch job machinery even for single object operations.

The new implementation provides a simple blocking copy for single objects, with ETL transform support for consistency and completeness.
This approach follows established S3 semantics that users already understand while delivering reduced overhead compared to full batch job engagement, consistent behavior for both local and remote operations, and proper error handling with immediate feedback.

ETL transforms can be applied during single object copy operations, maintaining consistency with multi-object transform operations while using the same runtime specifications and error reporting mechanisms.
The implementation integrates seamlessly with existing ETL infrastructure while avoiding the coordination overhead required for distributed batch processing.

### Commit Highlights

- [d4912c7ce](https://github.com/NVIDIA/aistore/commit/d4912c7ce): Implement single object copy in HTTP PUT requests
- [28fa7978f](https://github.com/NVIDIA/aistore/commit/28fa7978f): Add CLI support for bucket-to-bucket single object copy
- [ca095b1d1](https://github.com/NVIDIA/aistore/commit/ca095b1d1): Complete single object copy functionality
- [ae6eae377](https://github.com/NVIDIA/aistore/commit/ae6eae377): Refactor S3 copy handling with target handler optimization

<a name="backends"></a>
## 8. Cloud Backend Enhancements

AIStore 3.30 includes targeted improvements to cloud storage backend integration, with particular focus on Oracle Cloud Infrastructure multipart upload support and AWS configuration management.

### Oracle Cloud Infrastructure

OCI backend now supports multipart uploads as a native capability, enabling third-party S3 clients including boto3, s3cmd, and AWS CLI to perform multipart uploads against OCI backends without code changes. This enhancement improves upload performance for large objects while providing better reliability through chunked transfer and enhanced error recovery during transfer failures.

The OCI SDK has been upgraded to its latest version to date.

### AWS Configuration Management

AWS backend configuration gains support for loading multiple configuration files through the new `AIS_S3_CONFIG_DIR` environment variable. When set, AIStore scans the specified directory for files containing "conf" or "cred" in their names and loads them as AWS config and credentials files respectively. This simplifies deployment scenarios where multiple AWS configurations need to be managed across different environments or accounts.

The AWS SDK's built-in rate limiter has been disabled to prevent double-throttling scenarios where both AIStore and the SDK attempt to manage request rates simultaneously.

### Bug Fixes

Several object naming and encoding issues have been resolved, including fixes for double-escaped object names in certain edge cases, improved handling of special characters and Unicode in object names, and better URL encoding for complex object naming patterns that could cause accessibility issues.

### Commit Highlights

- [5bc11600](https://github.com/NVIDIA/aistore/commit/5bc11600): Implement OCI multipart upload support
- [f165eb1c](https://github.com/NVIDIA/aistore/commit/f165eb1c): Upgrade OCI SDK to version 65.95.2
- [9f46c652](https://github.com/NVIDIA/aistore/commit/9f46c652): Support multiple config and credentials files in specified directory
- [6d65bc65](https://github.com/NVIDIA/aistore/commit/6d65bc65): Disable AWS SDK rate limiter to prevent conflicts

<a name="bug-and-security"></a>
## 9. Bug and Security Fixes

AIStore 3.30 includes various bug fixes and security improvements addressing CLI usability, archive handling, testing stability, and filesystem edge cases.

### Security Improvements

Archive extraction operations now validate paths to prevent directory traversal attacks, checking for "../" and similar patterns and preventing writes outside intended directory boundaries across all supported archive formats.

Input validation has been also enhanced for object names and bucket operations, with better error handling for malformed requests.

### `ENOTDIR` Collision Auto-Healing

A filesystem collision-handling mechanism has been added to address a specific edge case in distributed object storage. The problem occurs when a directory tree like `aaa/bbb/ccc/` containing many objects is being populated (through PUTs or cold GETs), but an object named `aaa/bbb` also exists as a regular file. Once this file lands on a target, all subsequent attempts to write into the `aaa/bbb/` path will fail (on that specific target).

The auto-healing mechanism detects these collisions and automatically moves the conflicting file to the system trash, allowing normal directory operations to proceed. The system backtracks through the destination path to identify the culprit file, renames it with a timestamped prefix, and moves it to the deleted objects area where it remains until admin space cleanup or space watermark triggers removal. This ensures that directory hierarchies can be established even when conflicting objects exist, particularly important for remote bucket operations where such naming conflicts are more likely to occur.

### CLI and Test Fixes

Several CLI usability issues have been resolved including ignored `--evict` flags in certain command combinations, incorrect `--no-header` flag behavior, and JSON output formatting problems. Single object copy operations now properly validate destination bucket existence, fixing silent failures where operations would return success responses even when the destination bucket didn't exist. Note that bulk copy operations (`ais cp source-bucket destination-bucket`) will create the destination bucket if it doesn't exist, but single object copies require the destination bucket to exist beforehand.

ETL test infrastructure has been stabilized with better isolation and resource management, while archive format handling fixes address LZ4 and TGZ closing order issues that could cause corruption. Prometheus metric updates for node state and disk gauges have been corrected to properly reflect current system status.

Connection handling improvements eliminate race conditions in idle connection management and fix timeout handling that was causing false positives during long-running operations.

### Commit Highlights

- [1a9805a17](https://github.com/NVIDIA/aistore/commit/1a9805a17): Auto-heal ENOTDIR prefix collisions on remote buckets
- [1f838013f](https://github.com/NVIDIA/aistore/commit/1f838013f): Validate destination bucket existence in single object copy operations
- [71f3c21f](https://github.com/NVIDIA/aistore/commit/71f3c21f): Fix Prometheus metric updates for node state and disk gauges
- [944dad485](https://github.com/NVIDIA/aistore/commit/944dad485): Implement directory traversal protection for archive operations
- [ecda9c966](https://github.com/NVIDIA/aistore/commit/ecda9c966): Fix evict flags being ignored in CLI operations
- [45633a75a](https://github.com/NVIDIA/aistore/commit/45633a75a): Fix archive closing order for LZ4/TGZ formats

<a name="build"></a>
## 10. Build & CI

AIStore 3.30 includes targeted improvements to build infrastructure and dependency management.

### macOS Support

Starting with version 3.30, macOS/arm64 CLI binaries are automatically built and included with GitHub release artifacts, improving accessibility for developers using Apple Silicon workstations.

### API Documentation

Initial OpenAPI generator work has been added to generate HTTP API documentation, available at https://aistore.nvidia.com/docs/api-documentation. This represents early-stage work toward automated API documentation generation.

### Dependency Updates

All open-source dependencies have been upgraded to their latest versions (except Kubernetes client libraries), bringing security patches, performance improvements, and compatibility updates across the codebase.

### Commit Highlights

- [2a223f2d](https://github.com/NVIDIA/aistore/commit/2a223f2d): Add automatic macOS/arm64 binary builds to GitHub releases
- [c72af159](https://github.com/NVIDIA/aistore/commit/c72af159): Add initial OpenAPI generator for HTTP API documentation
- [9a1c480d](https://github.com/NVIDIA/aistore/commit/9a1c480d): Upgrade all open-source packages except Kubernetes client

---

<a name="documentation"></a>
## 11. Documentation

AIStore 3.30 includes comprehensive documentation improvements reflecting new features and evolving best practices.

### ETL Documentation

The [ET CLI documentation](https://github.com/NVIDIA/aistore/blob/main/docs/cli/etl.md) has been completely rewritten with updated initialization methods, runtime spec examples, multi-document YAML support, and enhanced error handling guides. The [AIS ETL Webserver Framework](https://github.com/NVIDIA/aistore/blob/main/python/aistore/sdk/etl/webserver/README.md) documentation now includes quickstart guides and advanced usage patterns.

### New Operational Guides

**Idle Connection Management**: New comprehensive guide at [idle_connections.md](https://github.com/NVIDIA/aistore/blob/main/docs/idle_connections.md) covering connection lifecycle, server-side timeout configuration, performance tuning, and troubleshooting.

**Machine Learning Workflows**: New [docs/cli/ml.md](https://github.com/NVIDIA/aistore/blob/main/docs/cli/ml.md) with detailed guides for `ais ml get-batch` and `lhotse‑get-batch` commands, manifest formats, and best practices.

### CLI and Configuration Updates

Enhanced CLI help text across multiple commands with better examples, error handling documentation, and parameter descriptions. Updated [advanced CLI features](https://github.com/NVIDIA/aistore/blob/main/docs/cli/advanced.md) documentation includes the new `check-lock` functionality.

AWS backend documentation has been enhanced with multiple config file support via `AIS_S3_CONFIG_DIR`, improved profile handling, and better credential chain documentation.

### Python SDK Documentation

Enhanced API documentation covers new BatchLoader capabilities, streaming patterns, and updated retry configuration alongside ETL framework improvements.

### Commit Highlights

- [663d9d4b3](https://github.com/NVIDIA/aistore/commit/663d9d4b3): Complete ETL CLI documentation rewrite
- [20157ebc0](https://github.com/NVIDIA/aistore/commit/20157ebc0): Add idle connections management guide
- [304d665f1](https://github.com/NVIDIA/aistore/commit/304d665f1): Add ETL multi-document YAML usage notes

---

<a name="deprecations"></a>
## 12. Deprecations & Compatibility

StatsD has been already **disabled by default** in v3.29, with Prometheus and OpenTelemetry remaining our default and recommended monitoring integration.

> Note: StatsD support will be completely removed in the Fall 2025 release to further streamline our monitoring architecture.

The CLI interface has been unified around the `--spec` parameter for request files, providing consistent behavior across all commands that accept specification files. This change improves the user experience by eliminating parameter name variations that existed in previous versions.

ETL metadata (that includes existing ETL job specifications) has been version-bumped to support the new transaction-safe protocol. Clusters must achieve uniform version status before starting new ETL operations to ensure consistent behavior across all nodes.

**ETL `init_code` Removal**: The deprecated `init_code` method for ETL initialization has been completely removed. Users must migrate to the `init_class` method or spec-based initialization. This is a breaking change for ETL workflows still using the legacy `init_code` approach.

### Commit Highlights

- [1a706d3a](https://github.com/NVIDIA/aistore/commit/1a706d3a): StatsD deprecation notice with migration timeline
- [47463a7](https://github.com/NVIDIA/aistore/commit/47463a7): Unify CLI spec parameter across all commands
- [fe453772](https://github.com/NVIDIA/aistore/commit/fe453772): Version ETL metadata for 2-PC compatibility
- [7364d006b](https://github.com/NVIDIA/aistore/commit/7364d006b): Remove deprecated `init_code`; improve init error reporting


> **Full changelog** — `git log --oneline v1.3.29...v1.3.30` (≈ 310 commits).
>
> **Upgrade notes**: Rolling upgrade is supported from v3.29. Drain in‑flight ETL jobs before restarting nodes to ensure clean transitions.
